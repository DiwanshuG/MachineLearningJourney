{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e04d90-7071-4fa2-bd33-968a5b26433f",
   "metadata": {},
   "source": [
    "#### Mathematical formualation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48168ef3-8ced-4874-be4f-e515cd651b20",
   "metadata": {},
   "source": [
    "example : a dataset has 2 cols and 4 rows , we have to draw a regression line[best fit] without using OLS method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcec7e-dccc-4760-80fd-27e69a882ce1",
   "metadata": {},
   "source": [
    "##### Assumption:\n",
    "\n",
    "For now, assume we already know the correct value of the slope \\( m \\).\n",
    "\n",
    "Using Ordinary Least Squares (OLS), we found:\n",
    "\n",
    "$$\n",
    "m = 78.35\n",
    "$$\n",
    "\n",
    "Now, we will focus on optimizing only \\( b \\) while keeping \\( m \\) fixed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f1d6e-71c5-4e97-b95f-1a8de3376d2a",
   "metadata": {},
   "source": [
    "#### Step 1 : \n",
    "start with a random b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb1edd-ce37-4dff-9950-594488561d3d",
   "metadata": {},
   "source": [
    "$$\n",
    "L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c44f07-db4c-46e5-9bbc-0de7bf55dbcb",
   "metadata": {},
   "source": [
    "since : $$\n",
    "\\hat{y}_i = m x_i + b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00eb6b7-7ca7-4829-a0f1-2c1ebccb2361",
   "metadata": {},
   "source": [
    "$$\n",
    "L = \\sum_{i=1}^{n} (y_i - m x_i - b)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a999db-7ed3-45c7-97b5-5bd9fdc793f4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dL}{db}\n",
    "=\n",
    "\\frac{d}{db}\n",
    "\\left(\n",
    "\\sum_{i=1}^{n}\n",
    "(y_i - m x_i - b)^2\n",
    "\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98127b80-ec79-4fb8-b1a5-e738ab974e83",
   "metadata": {},
   "source": [
    "$$\n",
    "=\n",
    "\\sum_{i=1}^{n}\n",
    "\\frac{d}{db}\n",
    "\\left(\n",
    "(y_i - m x_i - b)^2\n",
    "\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf14017b-7911-4a68-8643-56c5f0f61e7f",
   "metadata": {},
   "source": [
    "$$\n",
    "g = (y_i - m x_i - b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e1aaa-e32a-4239-ae7f-1269ad345375",
   "metadata": {},
   "source": [
    "$$\n",
    "=\n",
    "\\sum_{i=1}^{n}\n",
    "2(y_i - m x_i - b)\n",
    "\\cdot\n",
    "\\frac{d}{db}(y_i - m x_i - b)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87102014-3447-4412-92d0-d9363d988600",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{d}{db}(y_i - m x_i - b) = -1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f05dc-73a2-46b8-8839-fca07c1c66f9",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dL}{db}\n",
    "=\n",
    "-2\n",
    "\\sum_{i=1}^{n}\n",
    "(y_i - m x_i - b)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47a5fc-23d6-46e0-939b-350db80ed8c9",
   "metadata": {},
   "source": [
    "### Evaluating the Derivative at \\( b = 0 \\) and \\( m = 78.35 \\)\n",
    "\n",
    "We know:\n",
    "\n",
    "$$\n",
    "\\frac{dL}{db}\n",
    "=\n",
    "-2 \\sum_{i=1}^{n} (y_i - m x_i - b)\n",
    "$$\n",
    "\n",
    "Substitute \\( m = 78.35 \\) and \\( b = 0 \\):\n",
    "\n",
    "$$\n",
    "\\frac{dL}{db}\n",
    "=\n",
    "-2 \\sum_{i=1}^{n} \\left( y_i - 78.35 x_i - 0 \\right)\n",
    "$$\n",
    "\n",
    "Simplifying:\n",
    "\n",
    "$$\n",
    "\\frac{dL}{db}\n",
    "=\n",
    "-2 \\sum_{i=1}^{n} \\left( y_i - 78.35 x_i \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9c198-3519-480d-96f9-973aa1bda7dd",
   "metadata": {},
   "source": [
    "### Gradient Descent (Single Parameter Version)\n",
    "\n",
    "```python\n",
    "for i in range(epochs):\n",
    "    b_new = b_old - lr * slope\n",
    "    b_old = b_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d7f96-45b8-4d8c-ac28-4890a6c2d18a",
   "metadata": {},
   "source": [
    "# Mathematics Behind Gradient Descent for Linear Regression\r\n",
    "\r\n",
    "## 1. Model Definition\r\n",
    "\r\n",
    "For Simple Linear Regression:\r\n",
    "\r\n",
    "ŷ = mx + b\r\n",
    "\r\n",
    "Where:\r\n",
    "- m = slope  \r\n",
    "- b = intercept  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 2. Loss Function (Mean Squared Error)\r\n",
    "\r\n",
    "We use the Mean Squared Error (MSE) as the loss function:\r\n",
    "\r\n",
    "L(m, b) = (1/n) Σ (yi − (mxi + b))²\r\n",
    "\r\n",
    "Where:\r\n",
    "- n = number of data points  \r\n",
    "- yi = actual value  \r\n",
    "- mxi + b = predicted value  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 3. Partial Derivative with respect to m\r\n",
    "\r\n",
    "Differentiate L(m, b) with respect to m:\r\n",
    "\r\n",
    "∂L/∂m = ∂/∂m [ (1/n) Σ (yi − (mxi + b))² ]\r\n",
    "\r\n",
    "Using the chain rule:\r\n",
    "\r\n",
    "∂L/∂m = (1/n) Σ 2(yi − (mxi + b)) (−xi)\r\n",
    "\r\n",
    "Simplifying:\r\n",
    "\r\n",
    "∂L/∂m = (−2/n) Σ xi (yi − (mxi + b))\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 4. Partial Derivative with respect to b\r\n",
    "\r\n",
    "Differentiate L(m, b) with respect to b:\r\n",
    "\r\n",
    "∂L/∂b = ∂/∂b [ (1/n) Σ (yi − (mxi + b))² ]\r\n",
    "\r\n",
    "Using the chain rule:\r\n",
    "\r\n",
    "∂L/∂b = (1/n) Σ 2(yi − (mxi + b)) (−1)\r\n",
    "\r\n",
    "Simplifying:\r\n",
    "\r\n",
    "∂L/∂b = (−2/n) Σ (yi − (mxi + b))\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 5. Gradient Descent Update Rule\r\n",
    "\r\n",
    "Gradient Descent updates parameters using:\r\n",
    "\r\n",
    "θ = θ − η (∂L/∂θ)\r\n",
    "\r\n",
    "So for m:\r\n",
    "\r\n",
    "m = m − η (∂L/∂m)\r\n",
    "\r\n",
    "m = m − η [ (−2/n) Σ xi (yi − (mxi + b)) ]\r\n",
    "\r\n",
    "m = m + (2η/n) Σ xi (yi − (mxi + b))\r\n",
    "\r\n",
    "For b:\r\n",
    "\r\n",
    "b = b − η (∂L/∂b)\r\n",
    "\r\n",
    "b = b − η [ (−2/n) Σ (yi − (mxi + b)) ]\r\n",
    "\r\n",
    "b = b + (2η/n) Σ (yi − (mxi + b))\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 6. Final Update Equations\r\n",
    "\r\n",
    "m := m + (2η/n) Σ xi (yi − ŷi)\r\n",
    "\r\n",
    "b := b + (2η/n) Σ (yi − ŷi)\r\n",
    "\r\n",
    "Where:\r\n",
    "\r\n",
    "ŷi = mxi + b  \r\n",
    "η = learning rate  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Interpretation\r\n",
    "\r\n",
    "- (yi − ŷi) represents the prediction error.\r\n",
    "- The gradients determine the direction of steepest increase of the loss.\r\n",
    "- Subtracting the gradient moves the parameters in the direction of steepest decrease.\r\n",
    "- The learning rate η controls how large each update step is.\r\n",
    "\r\n",
    "This iterative process continues until the loss function converges to a minimum, producing the best-fit line.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46946bd-1ccf-43a4-9380-488c75aa3c72",
   "metadata": {},
   "source": [
    "# Gradient Descent Update Equations for m and b\r\n",
    "\r\n",
    "## Model\r\n",
    "\r\n",
    "ŷ = mx + b  \r\n",
    "\r\n",
    "## Loss Function (Mean Squared Error)\r\n",
    "\r\n",
    "L(m, b) = (1/n) Σ (yi − ŷi)²\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Gradients\r\n",
    "\r\n",
    "∂L/∂m = (−2/n) Σ xi (yi − ŷi)\r\n",
    "\r\n",
    "∂L/∂b = (−2/n) Σ (yi − ŷi)\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Final Update Rules\r\n",
    "\r\n",
    "Using the Gradient Descent rule:\r\n",
    "\r\n",
    "θ := θ − η (∂L/∂θ)\r\n",
    "\r\n",
    "### Update for m\r\n",
    "\r\n",
    "m := m − η (∂L/∂m)\r\n",
    "\r\n",
    "m := m − η [ (−2/n) Σ xi (yi − ŷi) ]\r\n",
    "\r\n",
    "m := m + (2η/n) Σ xi (yi − ŷi)\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Update for b\r\n",
    "\r\n",
    "b := b − η (∂L/∂b)\r\n",
    "\r\n",
    "b := b − η [ (−2/n) Σ (yi − ŷi) ]\r\n",
    "\r\n",
    "b := b + (2η/n) Σ (yi − ŷi)\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Compact Final Form\r\n",
    "\r\n",
    "m_new = m_old + (2η/n) Σ xi (yi − (mxi + b))\r\n",
    "\r\n",
    "b_new = b_old + (2η/n) Σ (yi − (mxi + b))\r\n",
    "\r\n",
    "Where:\r\n",
    "- η = learning rate  \r\n",
    "- n = number of samples  \r\n",
    "- (yi − ŷi) = prediction error  \r\n",
    "\r\n",
    "These equations are applied iteratively until convergence.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904973c-02ea-4cfe-bd55-ee96824db74b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
