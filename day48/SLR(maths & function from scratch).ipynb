{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2d6951b3-bb31-47bc-9b27-78e1ff76165b",
   "metadata": {},
   "source": [
    "package vs cgpa "
   ]
  },
  {
   "cell_type": "raw",
   "id": "da9c5dbc-207f-420b-9883-629e670926ae",
   "metadata": {},
   "source": [
    "we have to draw a best fit line , as y = mx + b"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76de5cca-cf05-4435-9f4b-9fbccb2e42f5",
   "metadata": {},
   "source": [
    "we have to find that value of m and b with which we can draw a best line of linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501ba3a-4940-48dd-93fc-3909e57f5b2b",
   "metadata": {},
   "source": [
    "The two ways are:\n",
    "\n",
    " - Closed-form / Analytical solution (Direct formula)\n",
    " - Optimization approach (Gradient Descent)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89b5e2d6-2264-4118-8afd-f22fc6ed0654",
   "metadata": {},
   "source": [
    "in higher dimension we should prefer gradiwnt descent :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42508851-f136-425b-abec-99f514b94ba3",
   "metadata": {},
   "source": [
    "### Closed-form solution (Direct math)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db48637c-31c1-4887-b593-b4ada6c0a0fe",
   "metadata": {},
   "source": [
    "This is the formula-based method.\n",
    "The best-fit line must pass through the point: \n",
    "          (xˉ,yˉ​)\n",
    "And the slope comes from covariance / variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c264968-129a-455c-8712-3036e3132f26",
   "metadata": {},
   "source": [
    "## Formulas for Simple Linear Regression\r\n",
    "\r\n",
    "### Slope (m)\r\n",
    "$$\r\n",
    "m = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}\r\n",
    "$$\r\n",
    "\r\n",
    "### Intercept (b)\r\n",
    "$$\r\n",
    "b = \\bar{y} - m\\bar{x}\r\n",
    "$$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be8160-5017-4c4e-aab6-6b46b865926f",
   "metadata": {},
   "source": [
    "## Explanation of the Formulas\r\n",
    "\r\n",
    "- $x_i$ and $y_i$ represent individual data points from the dataset.\r\n",
    "- $\\bar{x}$ is the mean (average) of the input variable $X$.\r\n",
    "- $\\bar{y}$ is the mean (average) of the target variable $Y$.\r\n",
    "\r\n",
    "## Interpretation of Slope ($m$)\r\n",
    "\r\n",
    "- The numerator  \r\n",
    "  $$\r\n",
    "  \\sum (x_i - \\bar{x})(y_i - \\bar{y})\r\n",
    "  $$\r\n",
    "  represents the **covariance between $X$ and $Y$**, which measures how $X$ and $Y$ vary together.\r\n",
    "\r\n",
    "- The denominator  \r\n",
    "  $$\r\n",
    "  \\sum (x_i - \\bar{x})^2\r\n",
    "  $$\r\n",
    "  represents the **variance of $X$**, which measures how $X$ varies on its own.\r\n",
    "\r\n",
    "- The slope $m$ indicates **how much $Y$ changes for a unit change in $X$**.\r\n",
    "\r\n",
    "## Interpretation of Intercept ($b$)\r\n",
    "\r\n",
    "- The intercept is calculated as:\r\n",
    "  $$\r\n",
    "  b = \\bar{y} - m\\bar{x}\r\n",
    "  $$\r\n",
    "\r\n",
    "- It ensures that the regression line passes through the point $(\\bar{x}, \\bar{y})$.\r\n",
    "- It represents the predicted value of $Y$ when $X = 0$.\r\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f69f9699-1328-47ea-b939-255f498a34e2",
   "metadata": {},
   "source": [
    "for example we have a best fit line : and each points(x1,x2,x3,x4............) are d1 , d2 , d3, d4 ....... distance from the line repectively ,\n",
    "\n",
    "E = (d1)^2 + (d2)^2  + (d3)^2  + .............  (dn)^2      [total error : E]\n",
    "\n",
    "why we are not using mod |d1| : \n",
    "  reason 1 :  for  outlier treatment\n",
    "  reason 2 :  in future we have to differentiate this equation : as mod function is continous but not differentiable at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f851bc2-6161-44d7-b22a-7667b8b24775",
   "metadata": {},
   "source": [
    "### Total Error (E)\n",
    "\n",
    "$$\n",
    "E = \\sum_{i=1}^{n} d_i^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68fd06dd-6c5c-44af-a668-0a01360e6594",
   "metadata": {},
   "source": [
    "we have to find the m & b which minimizing the error "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cb229fc-e86d-413c-b4af-896e57874382",
   "metadata": {},
   "source": [
    "what distance actually showing : according to my data : the actual package is di distance from predicted package : \n",
    "\n",
    "means that :  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efda24f-16c4-4069-a77b-e21aa1770b13",
   "metadata": {},
   "source": [
    "### Error Term ($d_i$)\n",
    "\n",
    "$$\n",
    "d_i = y_i - \\hat{y}_i\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $y_i$ is the actual value  \n",
    "- $\\hat{y}_i$ is the predicted value given by the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3307f1d-9b9c-498b-8133-f9dd5ea09e54",
   "metadata": {},
   "source": [
    "1) new formula : \n",
    "\n",
    "$$\n",
    "E[total error] = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "we have to find the m, b for this formula so that E is minimun but where is m , b\n",
    "$$\n",
    " y = m*x_i + b \n",
    "$$\n",
    "\n",
    "$$\n",
    " E(m,b) =  \\sum_{i=1}^{n} (y_i -( m*x_i + b  ))^2\n",
    "$$\n",
    "\n",
    "- we have to minimize this\n",
    "\n",
    "$$\n",
    " E(m,b) =  \\sum_{i=1}^{n} (y_i - m*x_i - b  )^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c8da63b-eb89-4d0f-80d0-73d6d58aa7c2",
   "metadata": {},
   "source": [
    "why we use gradient descent in more than 2d space : as there are only two ways that error can be handle here maybe one is from changing the slope , and other by changing the intercept "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802e5e7-677f-4c73-aef0-a72388840637",
   "metadata": {},
   "source": [
    "## Final Formula for Slope ($m$) in Simple Linear Regression\n",
    "\n",
    "$$\n",
    "m = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}\n",
    "         {\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6350b87d-8dfe-47fb-9f9a-de649a016a26",
   "metadata": {},
   "source": [
    "## Linear Regression: Finding Parameters $m$ and $b$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Case 1: Linear Regression with Intercept Fixed at Zero ($b = 0$)\r\n",
    "\r\n",
    "When the intercept is assumed to be zero, the linear regression model becomes:\r\n",
    "\r\n",
    "$$\r\n",
    "\\hat{y} = mx\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Error Function\r\n",
    "\r\n",
    "The total squared error is given by:\r\n",
    "\r\n",
    "$$\r\n",
    "E(m) = \\sum_{i=1}^{n} (y_i - m x_i)^2\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Minimization of Error\r\n",
    "\r\n",
    "To find the optimal value of $m$, we differentiate the error function with respect to $m$ and set it equal to zero.\r\n",
    "\r\n",
    "#### Step 1: Differentiate with respect to $m$\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{dE}{dm}\r\n",
    "= \\sum_{i=1}^{n} 2 (y_i - m x_i)(-x_i)\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Step 2: Set derivative equal to zero\r\n",
    "\r\n",
    "$$\r\n",
    "\\sum_{i=1}^{n} x_i (y_i - m x_i) = 0\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Step 3: Expand the summation\r\n",
    "\r\n",
    "$$\r\n",
    "\\sum_{i=1}^{n} x_i y_i - m \\sum_{i=1}^{n} x_i^2 = 0\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Step 4: Solve for $m$\r\n",
    "\r\n",
    "$$\r\n",
    "m = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_i^2}\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Final Result (Intercept Fixed at Zero)\r\n",
    "\r\n",
    "$$\r\n",
    "\\boxed{m = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_i^2}}\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Case 2: Linear Regression with Intercept ($b \\neq 0$)\r\n",
    "\r\n",
    "The general linear regression model is:\r\n",
    "\r\n",
    "$$\r\n",
    "\\hat{y} = m x + b\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Error Function\r\n",
    "\r\n",
    "The total squared error is defined as:\r\n",
    "\r\n",
    "$$\r\n",
    "E(m,b) = \\sum_{i=1}^{n} (y_i - m x_i - b)^2\r\n",
    "$$\r\n",
    "\r\n",
    "To find the optimal values of $m$ and $b$, we minimize the error by taking **partial derivatives** with respect to both parameters and setting them equal to zero.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Partial Derivative with respect to $m$\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{\\partial E}{\\partial m}\r\n",
    "= \\sum_{i=1}^{n} 2 (y_i - m x_i - b)(-x_i)\r\n",
    "$$\r\n",
    "\r\n",
    "Setting it to zero:\r\n",
    "\r\n",
    "$$\r\n",
    "\\sum_{i=1}^{n} x_i (y_i - m x_i - b) = 0\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Partial Derivative with respect to $b$\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{\\partial E}{\\partial b}\r\n",
    "= \\sum_{i=1}^{n} 2 (y_i - m x_i - b)(-1)\r\n",
    "$$\r\n",
    "\r\n",
    "Setting it to zero:\r\n",
    "\r\n",
    "$$\r\n",
    "\\sum_{i=1}^{n} (y_i - m x_i - b) = 0\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Final Insight\r\n",
    "\r\n",
    "Solving these two equations simultaneously gives the optimal values of:\r\n",
    "- $m$ (slope)\r\n",
    "- $b$ (intercept)\r\n",
    "\r\n",
    "These values minimize the total squared error and define the **best-fit regression line**.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8db812-86cd-4aa1-9b71-fd3fea474ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "955bf94f-0da3-4072-9859-9c6bca3e7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closed-form (analytical) implementation of Simple Linear Regression from scratch.\n",
    "class DiwLR:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.m = None\n",
    "        self.b = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        num = 0\n",
    "        den = 0\n",
    "        \n",
    "        for i in range(X_train.shape[0]):\n",
    "            num += (X_train[i] - X_train.mean()) * (y_train[i] - y_train.mean())\n",
    "            den += (X_train[i] - X_train.mean()) * (X_train[i] - X_train.mean())\n",
    "        \n",
    "        self.m = num / den\n",
    "        self.b = y_train.mean() - (self.m * X_train.mean())\n",
    "        \n",
    "        print(\"Slope (m):\", self.m)\n",
    "        print(\"Intercept (b):\", self.b)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return self.m * X_test + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62147fb0-886d-46de-86f9-26ac5136aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"placement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8569648-66b9-43c7-8ed7-2008bab31b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.89</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.12</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.82</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.42</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.94</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  package\n",
       "0  6.89     3.26\n",
       "1  5.12     1.98\n",
       "2  7.82     3.25\n",
       "3  7.42     3.67\n",
       "4  6.94     3.57"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4eb935d-1d55-430b-b837-b60170d950bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0].values\n",
    "y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "532f3714-1cc7-4070-ae69-abc2ff925891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.89, 5.12, 7.82, 7.42, 6.94, 7.89, 6.73, 6.75, 6.09, 8.31, 5.32,\n",
       "       6.61, 8.94, 6.93, 7.73, 7.25, 6.84, 5.38, 6.94, 7.48, 7.28, 6.85,\n",
       "       6.14, 6.19, 6.53, 7.28, 8.31, 5.42, 5.94, 7.15, 7.36, 8.1 , 6.96,\n",
       "       6.35, 7.34, 6.87, 5.99, 5.9 , 8.62, 7.43, 9.38, 6.89, 5.95, 7.66,\n",
       "       5.09, 7.87, 6.07, 5.84, 8.63, 8.87, 9.58, 9.26, 8.37, 6.47, 6.86,\n",
       "       8.2 , 5.84, 6.6 , 6.92, 7.56, 5.61, 5.48, 6.34, 9.16, 7.36, 7.6 ,\n",
       "       5.11, 6.51, 7.56, 7.3 , 5.79, 7.47, 7.78, 8.44, 6.85, 6.97, 6.94,\n",
       "       8.99, 6.59, 7.18, 7.63, 6.1 , 5.58, 8.44, 4.26, 4.79, 7.61, 8.09,\n",
       "       4.73, 6.42, 7.11, 6.22, 7.9 , 6.79, 5.83, 6.63, 7.11, 5.98, 7.69,\n",
       "       6.61, 7.95, 6.71, 5.13, 7.05, 7.62, 6.66, 6.13, 6.33, 7.76, 7.77,\n",
       "       8.18, 5.42, 8.58, 6.94, 5.84, 8.35, 9.04, 7.12, 7.4 , 7.39, 5.23,\n",
       "       6.5 , 5.12, 5.1 , 6.06, 7.33, 5.91, 6.78, 7.93, 7.29, 6.68, 6.37,\n",
       "       5.84, 6.05, 7.2 , 6.1 , 5.64, 7.14, 7.91, 7.19, 7.91, 6.76, 6.93,\n",
       "       4.85, 6.17, 5.84, 6.07, 5.66, 7.57, 8.28, 6.3 , 6.12, 7.37, 7.94,\n",
       "       7.08, 6.98, 7.38, 6.47, 5.95, 8.71, 7.13, 7.3 , 5.53, 8.93, 9.06,\n",
       "       8.21, 8.6 , 8.13, 8.65, 9.31, 6.22, 8.01, 6.93, 6.75, 7.32, 7.04,\n",
       "       6.29, 7.09, 8.15, 7.14, 6.19, 8.22, 5.88, 7.28, 7.88, 6.31, 7.84,\n",
       "       6.26, 7.35, 8.11, 6.19, 7.28, 8.25, 4.57, 7.89, 6.93, 5.89, 7.21,\n",
       "       7.63, 6.22])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27d59602-9494-4da8-9ba7-50ab0d39d367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26, 1.98, 3.25, 3.67, 3.57, 2.99, 2.6 , 2.48, 2.31, 3.51, 1.86,\n",
       "       2.6 , 3.65, 2.89, 3.42, 3.23, 2.35, 2.09, 2.98, 2.83, 3.16, 2.93,\n",
       "       2.3 , 2.48, 2.71, 3.65, 3.42, 2.16, 2.24, 3.49, 3.26, 3.89, 3.08,\n",
       "       2.73, 3.42, 2.87, 2.84, 2.43, 4.36, 3.33, 4.02, 2.7 , 2.54, 2.76,\n",
       "       1.86, 3.58, 2.26, 3.26, 4.09, 4.62, 4.43, 3.79, 4.11, 2.61, 3.09,\n",
       "       3.39, 2.74, 1.94, 3.09, 3.31, 2.19, 1.61, 2.09, 4.25, 2.92, 3.81,\n",
       "       1.63, 2.89, 2.99, 2.94, 2.35, 3.34, 3.62, 4.03, 3.44, 3.28, 3.15,\n",
       "       4.6 , 2.21, 3.  , 3.44, 2.2 , 2.17, 3.49, 1.53, 1.48, 2.77, 3.55,\n",
       "       1.48, 2.72, 2.66, 2.14, 4.  , 3.08, 2.42, 2.79, 2.61, 2.84, 3.83,\n",
       "       3.24, 4.14, 3.52, 1.37, 3.  , 3.74, 2.82, 2.19, 2.59, 3.54, 4.06,\n",
       "       3.76, 2.25, 4.1 , 2.37, 1.87, 4.21, 3.33, 2.99, 2.88, 2.65, 1.73,\n",
       "       3.02, 2.01, 2.3 , 2.31, 3.16, 2.6 , 3.11, 3.34, 3.12, 2.49, 2.01,\n",
       "       2.48, 2.58, 2.83, 2.6 , 2.1 , 3.13, 3.89, 2.4 , 3.15, 3.18, 3.04,\n",
       "       1.54, 2.42, 2.18, 2.46, 2.21, 3.4 , 3.67, 2.73, 2.76, 3.08, 3.99,\n",
       "       2.85, 3.09, 3.13, 2.7 , 3.04, 4.08, 2.93, 3.33, 2.55, 3.91, 3.82,\n",
       "       4.08, 3.98, 3.6 , 3.52, 4.37, 2.87, 3.76, 2.51, 2.56, 2.99, 3.5 ,\n",
       "       3.23, 3.64, 3.63, 3.03, 2.72, 3.89, 2.08, 2.72, 3.14, 3.18, 3.47,\n",
       "       2.44, 3.08, 4.06, 2.69, 3.48, 3.75, 1.94, 3.67, 2.46, 2.57, 3.24,\n",
       "       3.96, 2.33])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbddcc50-e718-496c-9575-71c38f7a5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d5986e5-14de-44f6-89bb-6d1a7b5040c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "394ba111-1893-4eaa-ac6b-ead8d3bb9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiwLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9591d77f-1db8-4515-b027-155556164daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (m): 0.5742564727019197\n",
      "Intercept (b): -1.0270069374542108\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f51c54e3-32cf-4d24-a370-73bdaca6c66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6605926-846b-4265-98f3-61e1ee8bb3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "584b6c3a-5a0c-484a-8ce9-aa88795a4862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.005375000000001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51d6a870-7b35-4528-88b6-ae41f7ba547f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.63"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9eac17b4-99cd-425c-97d6-fac8b3257a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.839345329174611\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703dedb-8473-4c0e-8d15-a711b75f3dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe790ae-f326-4134-a10e-6e82e2e369b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d6d3222-6b4d-48d8-80dc-510875dfdbc1",
   "metadata": {},
   "source": [
    "#### gradient descent–based Linear Regression from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21133c55-18ef-473e-8fc3-37d2ff7a4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent–based Linear Regression from scratch.\n",
    "class LinearRegressionScratch:    \n",
    "    def __init__(self, lr=0.01, epochs=1000):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.m = 0\n",
    "        self.b = 0\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n = len(X)\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            y_pred = self.m * X + self.b\n",
    "            \n",
    "            dm = (-2/n) * np.sum(X * (y - y_pred))\n",
    "            db = (-2/n) * np.sum(y - y_pred)\n",
    "            \n",
    "            self.m -= self.lr * dm\n",
    "            self.b -= self.lr * db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return self.m * X + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047576e-972b-4c36-bc78-95ba0cd4a0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
