{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc5da5b-e2c8-45c9-b503-bd5e0f9a352f",
   "metadata": {},
   "source": [
    "#### Vector Form of Loss (Ridge Regression)\n",
    "\n",
    "#### Scalar Form (Sum of Squared Errors)\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "#### Prediction in Vector Form\n",
    "\n",
    "$$\n",
    "\\hat{y} = Xw\n",
    "$$\n",
    "\n",
    "####  Loss in Vector Form\n",
    "\n",
    "$$\n",
    "L = (Xw - y)^T (Xw - y)\n",
    "$$\n",
    "\n",
    "####  L2 Regularization Term\n",
    "\n",
    "$$\n",
    "\\lambda \\|w\\|^2\n",
    "$$\n",
    "\n",
    "Since,\n",
    "\n",
    "$$\n",
    "\\|w\\|^2 = w^T w\n",
    "$$\n",
    "\n",
    "####  Final Ridge Regression Loss\n",
    "\n",
    "$$\n",
    "L = (Xw - y)^T (Xw - y) + \\lambda w^T w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a3f7d-1d02-4a70-bcc2-bcec8b6e2090",
   "metadata": {},
   "source": [
    "##### if x1, x2 ,x3 x4 .....xn are input columns\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "x_1^{(1)} & x_2^{(1)} & x_3^{(1)} & \\dots & x_n^{(1)} \\\\\n",
    "x_1^{(2)} & x_2^{(2)} & x_3^{(2)} & \\dots & x_n^{(2)} \\\\\n",
    "x_1^{(3)} & x_2^{(3)} & x_3^{(3)} & \\dots & x_n^{(3)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_1^{(m)} & x_2^{(m)} & x_3^{(m)} & \\dots & x_n^{(m)}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b473a04-cb2b-43b2-bdb3-be57327ec2f6",
   "metadata": {},
   "source": [
    "#### Gradient Descent Update Rule\r\n",
    "\r\n",
    "$$\r\n",
    "w_{\\text{new}} = w_{\\text{old}} - \\eta \\frac{\\partial L}{\\partial w}\r\n",
    "$$\r\n",
    "\r\n",
    "Now we compute the gradient \\( \\frac{\\partial L}{\\partial w} \\) for Ridge Regression.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Ridge Loss Function (Vector Form)\r\n",
    "\r\n",
    "$$\r\n",
    "L = (Xw - y)^T (Xw - y) + \\lambda w^T w\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Gradient of the Loss Function\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{\\partial L}{\\partial w}\r\n",
    "=\r\n",
    "\\frac{\\partial}{\\partial w}\r\n",
    "\\left[\r\n",
    "(Xw - y)^T (Xw - y)\r\n",
    "+\r\n",
    "\\lambda w^T w\r\n",
    "\\right]\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Gradient of First Term\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{\\partial}{\\partial w}\r\n",
    "(Xw - y)^T (Xw - y)\r\n",
    "=\r\n",
    "2 X^T (Xw - y)\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Gradient of Regularization Term\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{\\partial}{\\partial w}\r\n",
    "\\lambda w^T w\r\n",
    "=\r\n",
    "2 \\lambda w\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Final Gradient\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{\\partial L}{\\partial w}\r\n",
    "=\r\n",
    "2 X^T (Xw - y)\r\n",
    "+\r\n",
    "2 \\lambda w\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Final Weight Update Rule for Ridge Regression\r\n",
    "\r\n",
    "$$\r\n",
    "w_{\\text{new}}\r\n",
    "=\r\n",
    "w_{\\text{old}}\r\n",
    "-\r\n",
    "\\eta\r\n",
    "\\left(\r\n",
    "2 X^T (Xw - y)\r\n",
    "+\r\n",
    "2 \\lambda w\r\n",
    "\\right)\r\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0499fb-48c2-476b-a36a-e50e7e99fb26",
   "metadata": {},
   "source": [
    "# OR........"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9bad9-9e43-4be7-b31a-21f8f1e58613",
   "metadata": {},
   "source": [
    "#### Ridge Loss Function (with 1/2 scaling)\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{2}(Xw - y)^T (Xw - y) + \\frac{1}{2}\\lambda w^T w\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 1: Expand the Quadratic Term\n",
    "\n",
    "First rewrite:\n",
    "\n",
    "$$\n",
    "(Xw - y)^T = w^T X^T - y^T\n",
    "$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\n",
    "L =\n",
    "\\frac{1}{2}\n",
    "(w^T X^T - y^T)(Xw - y)\n",
    "+\n",
    "\\frac{1}{2}\\lambda w^T w\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Multiply the Terms\n",
    "\n",
    "$$\n",
    "L =\n",
    "\\frac{1}{2}\n",
    "\\left[\n",
    "w^T X^T X w\n",
    "-\n",
    "w^T X^T y\n",
    "-\n",
    "y^T X w\n",
    "+\n",
    "y^T y\n",
    "\\right]\n",
    "+\n",
    "\\frac{1}{2}\\lambda w^T w\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Take Derivative w.r.t. w\n",
    "\n",
    "Now differentiate term-by-term.\n",
    "\n",
    "1) $$ \\frac{\\partial}{\\partial w} (w^T X^T X w) = 2 X^T X w $$\n",
    "\n",
    "2) $$ \\frac{\\partial}{\\partial w} (w^T X^T y) = X^T y $$\n",
    "\n",
    "3) $$ \\frac{\\partial}{\\partial w} (y^T X w) = X^T y $$\n",
    "\n",
    "4) $$ \\frac{\\partial}{\\partial w} (y^T y) = 0 $$\n",
    "\n",
    "5) $$ \\frac{\\partial}{\\partial w} \\left( \\frac{1}{2}\\lambda w^T w \\right) = \\lambda w $$\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 4: Combine Everything\n",
    "\n",
    "Because of the 1/2 in front, the 2 cancels.\n",
    "\n",
    "Final gradient:\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dw}\n",
    "=\n",
    "X^T X w\n",
    "-\n",
    "X^T y\n",
    "+\n",
    "\\lambda w\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Final Compact Form\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dw}\n",
    "=\n",
    "X^T (Xw - y)\n",
    "+\n",
    "\\lambda w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc030c0f-04a9-4084-8b53-5dc8a3fc5942",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{\\text{new}} = w_{\\text{old}} - \\eta \\frac{\\partial L}{\\partial w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397da47-a5e1-4605-af23-f3b35417b547",
   "metadata": {},
   "source": [
    "## let's code this in python "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f12104ce-54b9-4510-b506-51f16a9b1089",
   "metadata": {},
   "source": [
    "We’ll first implement our own Ridge Regression (Gradient Descent version) on the diabetes dataset, then you can compare it with SGDRegressor and Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "818ff8c5-986e-4046-a4a6-22f11e6faed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SGDRegressor (L2 = Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a04b35a2-eca3-4361-94c6-537e4c58e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.4226329657491993\n",
      "[ -21.78308475 -118.38584487  388.45896744  193.4126863    -4.87454601\n",
      "  -68.27275091 -175.55323483  141.57747142  354.10451479  100.16440325]\n",
      "[177.85718022]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=43\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg = SGDRegressor(\n",
    "    penalty='l2',\n",
    "    max_iter=500,\n",
    "    eta0=0.1,\n",
    "    learning_rate='constant',\n",
    "    alpha=0.001\n",
    ")\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"R2 score\", r2_score(y_test, y_pred))\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "043dc57b-91de-4058-8308-ca699a2f3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Ridge (Closed-form / Solver-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258770d8-7264-4559-bf57-de5848f4a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.5421306472529078\n",
      "[ -60.55051435 -225.36087698  529.87642791  259.28548334 -738.97717811\n",
      "  407.97223878  105.56321825  214.51629966  795.66969963   35.44396968]\n",
      "152.0759468102823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "reg = Ridge(\n",
    "    alpha=0.001,\n",
    "    max_iter=500,\n",
    "    solver='sparse_cg'\n",
    ")\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"R2 score\", r2_score(y_test, y_pred))\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287dd0c-e20d-4042-927d-27c9c13b8014",
   "metadata": {},
   "source": [
    "| Situation            | Best Solver    |\n",
    "| -------------------- | -------------- |\n",
    "| Small dataset        | `svd`          |\n",
    "| Medium dense dataset | `cholesky`     |\n",
    "| Large sparse dataset | `sparse_cg`    |\n",
    "| Huge dataset         | `sag` / `saga` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397bc08-a49d-4316-aaab-7b5cf27a1ec6",
   "metadata": {},
   "source": [
    "| Solver      | Type                    | How It Works                            | Best For                             | Speed     | Stability         | Supports Sparse | Notes                              |\n",
    "| ----------- | ----------------------- | --------------------------------------- | ------------------------------------ | --------- | ----------------- | --------------- | ---------------------------------- |\n",
    "| `auto`      | Auto-select             | Chooses best solver automatically       | General use                          | Depends   | Depends           | Yes             | Default option                     |\n",
    "| `svd`       | Direct                  | Singular Value Decomposition            | Small datasets, ill-conditioned data | Slow      | ⭐⭐⭐⭐⭐ (Very High) | No              | Most numerically stable            |\n",
    "| `cholesky`  | Direct                  | Cholesky decomposition of (X^TX)        | Medium dense datasets                | Fast      | ⭐⭐⭐               | No              | Efficient but less stable than SVD |\n",
    "| `lsqr`      | Iterative               | Least Squares QR-based iterative method | Large datasets                       | Fast      | ⭐⭐⭐⭐              | Yes             | Memory efficient                   |\n",
    "| `sparse_cg` | Iterative               | Conjugate Gradient method               | Large sparse data                    | Fast      | ⭐⭐⭐⭐              | Yes             | No explicit matrix inverse         |\n",
    "| `sag`       | Iterative (GD-based)    | Stochastic Average Gradient             | Large datasets                       | Very Fast | ⭐⭐⭐               | Yes             | Requires feature scaling           |\n",
    "| `saga`      | Iterative (Improved GD) | Variant of SAG                          | Very large datasets                  | Very Fast | ⭐⭐⭐               | Yes             | Supports L1 & ElasticNet           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb56a5-2227-4466-8b79-7b4245b6bb83",
   "metadata": {},
   "source": [
    "## building own class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c7e6039-70e2-4f92-9c0b-fdf0ead3043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRidgeGD:\n",
    "    \n",
    "    def __init__(self, epochs=500, learning_rate=0.01, alpha=0.001):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        m, n = X_train.shape\n",
    "        \n",
    "        # Add bias column\n",
    "        X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "        \n",
    "        # Initialize theta\n",
    "        theta = np.zeros(n + 1)\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            \n",
    "            # Gradient core\n",
    "            gradient = X_train.T @ (X_train @ theta - y_train)\n",
    "            \n",
    "            # Regularization (DO NOT regularize bias)\n",
    "            reg = self.alpha * theta\n",
    "            reg[0] = 0\n",
    "            \n",
    "            gradient += reg\n",
    "            \n",
    "            # Average over samples\n",
    "            gradient = gradient / m\n",
    "            \n",
    "            # Update\n",
    "            theta = theta - self.learning_rate * gradient\n",
    "        \n",
    "        self.intercept_ = theta[0]\n",
    "        self.coef_ = theta[1:]\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return X_test @ self.coef_ + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "545eb80b-f320-4661-83b7-cba80372286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63fbf51b-ae36-4ce0-863a-24ead9939efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.5410641628046949\n",
      "[ 1.19597937  0.17851711  5.34158267  3.20284639  1.86339584  1.62023936\n",
      " -3.57840332  3.95766448  5.00484777  2.96974345]\n",
      "140.01445559898588\n"
     ]
    }
   ],
   "source": [
    "model = MyRidgeGD(epochs=1000, learning_rate=0.1, alpha=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n",
    "\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774552e-c96e-4d22-b3b7-08ced584b4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
