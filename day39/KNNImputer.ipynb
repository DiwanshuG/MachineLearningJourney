{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdef0ff6-e8be-45e6-bf60-457596f108e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Its a multivariate technique to fill the missing values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab0cd6f7-13ad-42ee-b784-378a99e88c09",
   "metadata": {},
   "source": [
    "Instead of guessing missing values, let neighbors decide.\n",
    "Smarter than mean/median when data has patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db110a91-b5d9-4b93-ac30-8d7957737618",
   "metadata": {},
   "source": [
    "## Working"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76f2b193-ffd8-4c5d-b8e9-f8f2c0f95de6",
   "metadata": {},
   "source": [
    "Idea:\n",
    "Missing values are filled using the values of the K nearest data points (neighbors) instead of a global average."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cacbe7bf-e4b8-4613-9d96-b7beeda699b6",
   "metadata": {},
   "source": [
    "Step-by-step working\n",
    "\n",
    "1Ô∏è‚É£ Find rows with missing values\n",
    "The algorithm identifies samples where a feature is missing.\n",
    "\n",
    "2Ô∏è‚É£ Measure distance\n",
    "It computes the distance (usually Euclidean) between this row and all other rows using only the non-missing features.\n",
    "\n",
    "3Ô∏è‚É£ Select K nearest neighbors\n",
    "The closest K rows (most similar data points) are selected.\n",
    "\n",
    "4Ô∏è‚É£ Impute the value\n",
    "For numerical data ‚Üí mean (or weighted mean) of neighbors\n",
    "For categorical data ‚Üí most frequent value (mode)\n",
    "\n",
    "5Ô∏è‚É£ Replace the missing value\n",
    "The calculated value is inserted into the missing position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efba40-6e4c-467f-8e68-cf3ade017d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K - number of nearest neighbors\n",
    "1) find K nearest neighbors\n",
    "2) find the values "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1643bca-1903-42e0-ae25-56e36af26333",
   "metadata": {},
   "source": [
    "üö´ Avoid when:\n",
    "\n",
    "Dataset is very large (slow)\n",
    "\n",
    "Data has many missing values\n",
    "\n",
    "Features are on different scales (without scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb36206-43a1-47ea-8f47-21e4552c1cf3",
   "metadata": {},
   "source": [
    "Why KNN Imputation is powerful üí°\n",
    "\n",
    "1)  Preserves data relationships\n",
    "2) Better than mean/median for non-linear patterns\n",
    "3)  Adapts locally instead of globally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d7c93-cc47-48e4-bc91-c388763b700e",
   "metadata": {},
   "source": [
    "## nan_euclidean"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d5431f3-7a18-47e4-9100-7d2114ee538c",
   "metadata": {},
   "source": [
    "nan_euclidean is a distance metric designed to work when data has missing values (NaNs)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd551ddd-b05d-4c46-9d3d-843ed05a4173",
   "metadata": {},
   "source": [
    "How nan_euclidean works \n",
    "Formula intuition (no heavy math)\n",
    "\n",
    "1) Compare only the features where BOTH rows have values\n",
    "2Ô∏è) Compute Euclidean distance on those features\n",
    "3Ô∏è) Scale the distance to account for missing features\n",
    "\n",
    "This scaling prevents rows with fewer features from looking artificially closer."
   ]
  },
  {
   "cell_type": "raw",
   "id": "975b3872-5302-4274-a65e-58bab5ab13fb",
   "metadata": {},
   "source": [
    "dist(x,y) = sqrt(weight * sq. distance from present coordinates) ,\n",
    "weight = Total number of coordinates / number of present coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d277e-0b6e-4236-ab81-6cd24aa659a8",
   "metadata": {},
   "source": [
    " ‚úÖ Advantages of nan_euclidean\n",
    "\n",
    "Ô∏è1) Works with missing values\n",
    "‚Üí Computes distance even when features contain NaN (huge win for real-world data).\n",
    "\n",
    "2Ô∏è) Fair comparison between samples\n",
    "‚Üí Ignores missing features but scales the distance, so rows with fewer values don‚Äôt look artificially closer.\n",
    "\n",
    "3Ô∏è) Default & reliable for KNN Imputer\n",
    "‚Üí Designed specifically for KNN-based imputation ‚Üí stable and well-tested.\n",
    "\n",
    "4Ô∏è)  Preserves local relationships\n",
    "‚Üí Uses nearby, similar data points instead of global statistics (mean/median).\n",
    "\n",
    "5Ô∏è)  No need to pre-impute\n",
    "‚Üí Distance calculation itself handles NaNs directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed563b9-0c73-48bf-8515-59dd0492fc05",
   "metadata": {},
   "source": [
    "‚ùå Disadvantages of nan_euclidean\n",
    "\n",
    "Ô∏è1) Sensitive to feature scale ‚ö†Ô∏è\n",
    "‚Üí Without scaling (StandardScaler / MinMaxScaler), large-value features dominate distance.\n",
    "\n",
    "2Ô∏è)  Slower on large datasets\n",
    "‚Üí Distance calculation for every row √ó every feature ‚Üí computationally expensive.\n",
    "\n",
    "3Ô∏è)  Performance drops with many NaNs\n",
    "‚Üí If very few common features exist, distance becomes unreliable.\n",
    "\n",
    "Ô∏è4)  Assumes numerical features\n",
    "‚Üí Not suitable for categorical data without proper encoding.\n",
    "\n",
    "5Ô∏è)  Not robust to outliers\n",
    "‚Üí Extreme values can heavily distort distance calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0999b4-5997-4642-87de-ead0cd11cf42",
   "metadata": {},
   "source": [
    "### KNN Distance-Based Weighting (Quick Note)\n",
    "\n",
    "In KNN, when `weights='distance'`, closer neighbors have more influence than farther ones.\n",
    "\n",
    "Each neighbor‚Äôs weight is calculated as:\n",
    "\n",
    "weight = 1 / distance\n",
    "\n",
    "The final imputed value is a weighted average:\n",
    "\n",
    "Imputed value =\n",
    "(Œ£ (value·µ¢ √ó 1 / distance·µ¢)) / (Œ£ (1 / distance·µ¢))\n",
    "\n",
    "This approach is better than uniform weighting because it preserves local data patterns by giving higher importance to nearby points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4b76d-32a3-4aec-af9d-126f30677c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
